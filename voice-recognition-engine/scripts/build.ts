/**
 * Build and development utilities for VoiceFlow Pro Voice Recognition Engine
 */

import { execSync } from 'child_process';
import { existsSync, mkdirSync, writeFileSync, readFileSync } from 'fs';
import { join, dirname } from 'path';

interface BuildConfig {
  outputDir: string;
  minify: boolean;
  sourcemap: boolean;
  target: string;
  format: 'esm' | 'cjs' | 'iife';
}

export class BuildManager {
  private config: BuildConfig;

  constructor(config: Partial<BuildConfig> = {}) {
    this.config = {
      outputDir: 'dist',
      minify: false,
      sourcemap: true,
      target: 'ES2020',
      format: 'esm',
      ...config
    };
  }

  async build(): Promise<void> {
    console.log('üöÄ Building VoiceFlow Pro Voice Recognition Engine...');
    
    try {
      // Ensure output directory exists
      if (!existsSync(this.config.outputDir)) {
        mkdirSync(this.config.outputDir, { recursive: true });
      }

      // Clean previous build
      this.cleanDist();

      // Compile TypeScript
      await this.compileTypeScript();

      // Create browser bundle
      await this.createBrowserBundle();

      // Generate type definitions
      await this.generateTypes();

      // Create UMD build
      await this.createUMDBuild();

      // Generate documentation
      await this.generateDocs();

      console.log('‚úÖ Build completed successfully!');
      console.log(`üì¶ Output directory: ${this.config.outputDir}`);
      
    } catch (error) {
      console.error('‚ùå Build failed:', error);
      throw error;
    }
  }

  private cleanDist(): void {
    console.log('üßπ Cleaning dist directory...');
    execSync('rm -rf dist/*', { stdio: 'inherit' });
  }

  private async compileTypeScript(): Promise<void> {
    console.log('üìù Compiling TypeScript...');
    
    const tscCommand = [
      'tsc',
      '--project', 'tsconfig.json',
      '--outDir', this.config.outputDir,
      '--declaration',
      '--declarationMap',
      '--sourceMap',
      '--removeComments'
    ];

    execSync(tscCommand.join(' '), { stdio: 'inherit' });
  }

  private async createBrowserBundle(): Promise<void> {
    console.log('üåê Creating browser bundle...');
    
    // Create a browser-specific entry point
    const browserEntry = `
      // VoiceFlow Pro Voice Recognition Engine - Browser Bundle
      // This file provides browser-compatible entry points
      
      import * as core from './index.js';
      
      // Export everything from the main module
      export * from './index.js';
      
      // Add browser-specific globals
      if (typeof window !== 'undefined') {
        window.VoiceFlowPro = core;
        window.VoiceFlowRecognition = core;
      }
      
      // Auto-initialize if running in browser
      if (typeof window !== 'undefined' && typeof document !== 'undefined') {
        document.addEventListener('DOMContentLoaded', () => {
          console.log('VoiceFlow Pro Voice Recognition Engine loaded');
        });
      }
    `;

    writeFileSync(join(this.config.outputDir, 'browser.js'), browserEntry);
  }

  private async generateTypes(): Promise<void> {
    console.log('üìã Generating TypeScript definitions...');
    
    // Type definitions are already generated by tsc --declaration
    // This is where we could add additional type generation if needed
  }

  private async createUMDBuild(): Promise<void> {
    console.log('üì¶ Creating UMD bundle...');
    
    const umdWrapper = `
      (function (global, factory) {
        typeof exports === 'object' && typeof module !== 'undefined' ? factory(exports) :
        typeof define === 'function' && define.amd ? define(['exports'], factory) :
        (factory((global.VoiceFlowPro = {})));
      }(this, (function (exports) {
        'use strict';

        // VoiceFlow Pro Voice Recognition Engine - UMD Bundle
        // This bundle provides compatibility for multiple module systems
        
        // Note: This is a placeholder UMD wrapper
        // In a real build, you would use a tool like Rollup or Webpack
        // to create a proper UMD bundle with all dependencies included
        
        exports.default = 'VoiceFlow Pro Voice Recognition Engine';
        exports.version = '1.0.0';
        
      })));
    `;

    writeFileSync(join(this.config.outputDir, 'voiceflow-pro.umd.js'), umdWrapper);
  }

  private async generateDocs(): Promise<void> {
    console.log('üìö Generating documentation...');
    
    // Create API documentation
    const docs = this.generateAPIDocs();
    writeFileSync(join(this.config.outputDir, 'API.md'), docs);
  }

  private generateAPIDocs(): string {
    return `# VoiceFlow Pro Voice Recognition Engine - API Reference

## Core Classes

### VoiceFlowPro
Main engine class for voice recognition operations.

\`\`\`typescript
class VoiceFlowPro {
  // Initialize the engine
  async initialize(language?: string): Promise<void>
  
  // Start voice recognition
  async startListening(config?: RecognitionConfig): Promise<void>
  
  // Stop voice recognition
  async stopListening(): Promise<void>
  
  // Set recognition language
  async setLanguage(languageCode: string): Promise<void>
  
  // Switch recognition engine
  async switchEngine(modelType: ModelType): Promise<void>
  
  // Register custom plugin
  async registerPlugin(plugin: VoiceRecognitionPlugin): Promise<void>
  
  // Get performance statistics
  getStatistics(): RecognitionStats
  
  // Event handlers
  onResult(callback: (result: SpeechRecognitionResult) => void): () => void
  onError(callback: (error: RecognitionError) => void): () => void
  onStart(callback: () => void): () => void
  onStop(callback: () => void): () => void
  onAudioMetrics(callback: (metrics: AudioMetrics) => void): () => void
  onLanguageDetected(callback: (language: Language) => void): () => void
  onEngineSwitched(callback: (model: ModelType) => void): () => void
}
\`\`\`

### VoiceUtils
Utility functions for common voice recognition tasks.

\`\`\`typescript
class VoiceUtils {
  // Check language support
  static isLanguageSupported(languageCode: string): boolean
  
  // Search for languages
  static searchLanguages(query: string): Language[]
  
  // Format transcription results
  static formatTranscript(result: SpeechRecognitionResult): string
  
  // Create voice command parser
  static createVoiceCommandParser(commands: { [key: string]: string }): (text: string) => string | null
  
  // Calculate average confidence
  static calculateAverageConfidence(results: SpeechRecognitionResult[]): number
  
  // Create confidence checker
  static createConfidenceChecker(minConfidence: number): (result: SpeechRecognitionResult) => boolean
}
\`\`\`

## Types and Interfaces

### RecognitionConfig
Configuration for voice recognition parameters.

\`\`\`typescript
interface RecognitionConfig {
  language: string;              // Language code (e.g., 'en-US')
  continuous: boolean;           // Continuous recognition mode
  interimResults: boolean;       // Include interim results
  maxAlternatives: number;       // Maximum alternative results
  confidenceThreshold: number;   // Minimum confidence threshold
  noiseReduction: boolean;       // Enable noise reduction
  autoLanguageDetection: boolean; // Automatic language detection
  realTimeTranscription: boolean; // Real-time processing
}
\`\`\`

### SpeechRecognitionResult
Result object from voice recognition.

\`\`\`typescript
interface SpeechRecognitionResult {
  transcript: string;           // Recognized text
  confidence: number;           // Confidence score (0-1)
  isFinal: boolean;            // Is this a final result
  timestamp: number;           // Recognition timestamp
  language: string;            // Detected language
  alternatives: Alternative[]; // Alternative transcriptions
  metadata: RecognitionMetadata; // Additional metadata
}
\`\`\`

## Engine Types

### ModelType
Available recognition engine models.

\`\`\`typescript
enum ModelType {
  WEB_SPEECH_API = 'web-speech-api',  // Browser native
  WHISPER_TINY = 'whisper-tiny',      // 75MB model
  WHISPER_BASE = 'whisper-base',      // 142MB model
  WHISPER_SMALL = 'whisper-small',    // 488MB model
  WHISPER_MEDIUM = 'whisper-medium',  // 1.5GB model
  WHISPER_LARGE = 'whisper-large'     // 3GB model
}
\`\`\`

## Language Support

The engine supports 150+ languages including:

### Major Languages
- English (en-US, en-GB, en-AU, etc.)
- Spanish (es-ES, es-MX, es-AR, etc.)
- French (fr-FR, fr-CA, fr-BE, etc.)
- German (de-DE, de-AT, de-CH, etc.)
- Italian (it-IT)
- Portuguese (pt-PT, pt-BR)
- Chinese (zh-CN, zh-TW)
- Japanese (ja-JP)
- Korean (ko-KR)
- Arabic (ar-SA, ar-EG, etc.)

### Regional Languages
See \`SUPPORTED_LANGUAGES\` constant for complete list.

## Error Handling

### RecognitionError
Error object for voice recognition failures.

\`\`\`typescript
class RecognitionError extends Error {
  code: string;        // Error code
  model?: ModelType;   // Engine that failed
  recoverable: boolean; // Can be automatically recovered
  
  constructor(
    message: string,
    code: string,
    model?: ModelType,
    recoverable: boolean = true
  )
}
\`\`\`

## Plugin System

### VoiceRecognitionPlugin
Interface for creating custom plugins.

\`\`\`typescript
interface VoiceRecognitionPlugin {
  name: string;        // Plugin name
  version: string;     // Plugin version
  
  initialize(): Promise<void>
  cleanup(): Promise<void>
  
  // Optional methods
  processAudio?(audioData: Float32Array): Promise<Float32Array>
  enhanceResult?(result: SpeechRecognitionResult): Promise<SpeechRecognitionResult>
  detectLanguage?(audioData: Float32Array): Promise<Language | null>
}
\`\`\`

## Examples

### Basic Usage
\`\`\`typescript
import { VoiceFlowPro } from 'voiceflow-voice-recognition-engine';

const engine = new VoiceFlowPro();
await engine.initialize('en-US');

engine.onResult((result) => {
  console.log('Transcript:', result.transcript);
  console.log('Confidence:', result.confidence);
});

await engine.startListening();
\`\`\`

### Advanced Configuration
\`\`\`typescript
import { createVoiceEngine, ModelType } from 'voiceflow-voice-recognition-engine';

const engine = createVoiceEngine({
  primaryEngine: ModelType.WHISPER_BASE,
  fallbackEngine: ModelType.WEB_SPEECH_API,
  autoEngineSelection: true,
  offlineFirst: true,
  qualityPreference: QualityLevel.EXCELLENT
});

await engine.initialize();
await engine.startListening({
  language: 'en-US',
  continuous: true,
  interimResults: true,
  confidenceThreshold: 0.7
});
\`\`\`

### Custom Plugin
\`\`\`typescript
class NoiseReductionPlugin implements VoiceRecognitionPlugin {
  name = 'advanced-noise-reduction';
  version = '1.0.0';
  
  async initialize(): Promise<void> {
    console.log('Noise reduction plugin initialized');
  }
  
  async processAudio(audioData: Float32Array): Promise<Float32Array> {
    // Apply noise reduction algorithm
    return this.reduceNoise(audioData);
  }
  
  async cleanup(): Promise<void> {
    console.log('Noise reduction plugin cleaned up');
  }
}

await engine.registerPlugin(new NoiseReductionPlugin());
\`\`\`

For more examples and detailed documentation, visit our [GitHub repository](https://github.com/voiceflow-pro/voice-recognition-engine).
`;
  }

  async watch(): Promise<void> {
    console.log('üëÄ Starting development watch mode...');
    
    // Run initial build
    await this.build();
    
    // Watch for changes (this is a simplified version)
    // In a real implementation, you'd use chokidar or similar
    console.log('üëÄ Watching for changes...');
    console.log('Press Ctrl+C to stop');
    
    // Keep the process running
    return new Promise(() => {});
  }

  async clean(): Promise<void> {
    console.log('üßπ Cleaning build artifacts...');
    execSync('rm -rf dist', { stdio: 'inherit' });
    console.log('‚úÖ Clean completed');
  }

  // Utility methods
  static async buildExamples(): Promise<void> {
    console.log('üìù Building examples...');
    
    const examplesDir = 'examples';
    const distExamplesDir = 'dist/examples';
    
    if (!existsSync(distExamplesDir)) {
      mkdirSync(distExamplesDir, { recursive: true });
    }
    
    // Copy examples
    execSync(`cp -r ${examplesDir}/* ${distExamplesDir}/`, { stdio: 'inherit' });
    
    console.log('‚úÖ Examples built');
  }
}

// CLI interface
if (require.main === module) {
  const args = process.argv.slice(2);
  const command = args[0];
  
  const buildManager = new BuildManager();
  
  switch (command) {
    case 'build':
      buildManager.build().catch(console.error);
      break;
    case 'watch':
      buildManager.watch().catch(console.error);
      break;
    case 'clean':
      buildManager.clean().catch(console.error);
      break;
    case 'examples':
      BuildManager.buildExamples().catch(console.error);
      break;
    default:
      console.log(`
VoiceFlow Pro Voice Recognition Engine - Build Manager

Commands:
  build     - Build the project
  watch     - Build and watch for changes
  clean     - Clean build artifacts
  examples  - Build examples

Usage:
  npm run build        # Build the project
  npm run dev          # Build and watch
  npm run clean        # Clean artifacts
      `);
  }
}

export { BuildManager };